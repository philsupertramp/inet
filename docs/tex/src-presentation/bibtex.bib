% Papers
@article{GIoU,
  author    = {Seyed Hamid Rezatofighi and
               Nathan Tsoi and
               JunYoung Gwak and
               Amir Sadeghian and
               Ian D. Reid and
               Silvio Savarese},
  title     = {Generalized Intersection over Union: {A} Metric and {A} Loss for Bounding
               Box Regression},
  journal   = {CoRR},
  volume    = {abs/1902.09630},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.09630},
  eprinttype = {arXiv},
  eprint    = {1902.09630},
  timestamp = {Tue, 21 May 2019 18:03:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-09630.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{AlexNet,
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    title = {ImageNet Classification with Deep Convolutional Neural Networks},
    year = {2012},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
    booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
    pages = {1097–1105},
    numpages = {9},
    location = {Lake Tahoe, Nevada},
    series = {NIPS'12}
}
@INPROCEEDINGS{Lecun99objectrecognition,
    author = {Yann Lecun and Patrick Haffner and Léon Bottou and Yoshua Bengio},
    title = {Object Recognition with Gradient-Based Learning},
    booktitle = {Contour and Grouping in Computer Vision},
    year = {1999},
    publisher = {Springer}
}
@misc{VGG16,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{MobileNet,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{SSD,
  author    = {Wei Liu and
               Dragomir Anguelov and
               Dumitru Erhan and
               Christian Szegedy and
               Scott E. Reed and
               Cheng{-}Yang Fu and
               Alexander C. Berg},
  title     = {{SSD:} Single Shot MultiBox Detector},
  journal   = {CoRR},
  volume    = {abs/1512.02325},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02325},
  eprinttype = {arXiv},
  eprint    = {1512.02325},
  timestamp = {Wed, 12 Feb 2020 08:32:49 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/LiuAESR15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{yolo,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{biomassPaper,
    doi = {10.1371/journal.pone.0185809},
    author = {Hallmann, Caspar A. AND Sorg, Martin AND Jongejans, Eelke AND Siepel, Henk AND Hofland, Nick AND Schwan, Heinz AND Stenmans, Werner AND Müller, Andreas AND Sumser, Hubert AND Hörren, Thomas AND Goulson, Dave AND de Kroon, Hans},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {More than 75 percent decline over 27 years in total flying insect biomass in protected areas},
    year = {2017},
    month = {10},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0185809},
    pages = {1-21},
    abstract = {Global declines in insects have sparked wide interest among scientists, politicians, and the general public. Loss of insect diversity and abundance is expected to provoke cascading effects on food webs and to jeopardize ecosystem services. Our understanding of the extent and underlying causes of this decline is based on the abundance of single species or taxonomic groups only, rather than changes in insect biomass which is more relevant for ecological functioning. Here, we used a standardized protocol to measure total insect biomass using Malaise traps, deployed over 27 years in 63 nature protection areas in Germany (96 unique location-year combinations) to infer on the status and trend of local entomofauna. Our analysis estimates a seasonal decline of 76%, and mid-summer decline of 82% in flying insect biomass over the 27 years of study. We show that this decline is apparent regardless of habitat type, while changes in weather, land use, and habitat characteristics cannot explain this overall decline. This yet unrecognized loss of insect biomass must be taken into account in evaluating declines in abundance of species depending on insects as a food source, and ecosystem functioning in the European landscape.},
    number = {10},

}

@article{iNat,
  author    = {Grant Van Horn and
               Oisin Mac Aodha and
               Yang Song and
               Alexander Shepard and
               Hartwig Adam and
               Pietro Perona and
               Serge J. Belongie},
  title     = {The iNaturalist Challenge 2017 Dataset},
  journal   = {CoRR},
  volume    = {abs/1707.06642},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06642},
  eprinttype = {arXiv},
  eprint    = {1707.06642},
  timestamp = {Tue, 08 Sep 2020 16:29:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HornASSAPB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{iNat-2021,
    title        = {iNaturalist 2021 Competition description},
    author       = {\url{https://github.com/visipedia/}},
    year         = 2021,
    howpublished = {\url{https://github.com/visipedia/inat_comp/blob/4ea5638e6f51c0a46c866305d6e0b640d40609d7/2021/README.md}}
}
@Article{neuron,
    author={McCulloch, Warren S.
    and Pitts, Walter},
    title={A logical calculus of the ideas immanent in nervous activity},
    journal={The bulletin of mathematical biophysics},
    year={1943},
    month={Dec},
    day={01},
    volume={5},
    number={4},
    pages={115-133},
    abstract={Because of the ``all-or-none'' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
    issn={1522-9602},
    doi={10.1007/BF02478259},
    url={https://doi.org/10.1007/BF02478259}
}



@article{RidgeRegression,
 ISSN = {00401706},
 URL = {http://www.jstor.org/stable/1267351},
 abstract = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X′X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X′X to obtain biased estimates with smaller mean square error.},
 author = {Arthur E. Hoerl and Robert W. Kennard},
 journal = {Technometrics},
 number = {1},
 pages = {55--67},
 publisher = {[Taylor & Francis, Ltd., American Statistical Association, American Society for Quality]},
 title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
 volume = {12},
 year = {1970}
}

@misc{LinReg1,
    title        = {Yale University – Fall 1997-98, Statistics 101-103, Introduction to Statistics: Linear Regression},
    author       = {Mr. Andrew Barron, Mr. Junhyong Kim},
    year         = 1997,
    publisher = "Yale University",
    howpublished = {\url{http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm}}
}

@misc{LinReg2,
    title        = {scikit-learn Examples: Linear Regression Example},
    author       = {scikit-learn},
    year         = 2022,
    howpublished = {\url{https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html}}
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2022-03-22},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
}

@article{taxonomy,
 title={What is taxonomy? – An overview with myriapodological examples},
 author={Henrik Enghoff},
 journal={SOIL ORGANISMS},
 volume={81},
 pages={441--451},
 year={2009}
}
@article{pca,
 title={A Tutorial on {P}rincipal {C}omponent {A}nalysis},
 author={Jonathon Shlens},
 year = 2005,
 howpublished = {\url{https://www.cs.cmu.edu/~elaw/papers/pca.pdf}}
}

@article{yolo-blog,
 title={{H}ow to {T}rain {Y}{O}{L}{O} v5 on a {C}ustom {D}ataset},
 author={Ayoosh Kathuria},
 year = 2021,
 howpublished = {\url{https://blog.paperspace.com/train-yolov5-custom-data/}}
}
% Weblinks

@misc{BayesianOptimization,
    title        = {CSE 515T: Bayesian Methods in Machine Learning – Spring 2015, Lecture 12: Bayesian Optimization},
    author       = {Professor Roman Garnett},
    year         = 2015,
    howpublished = {\url{https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf}}
}

@misc{KI-Leuchtturm,
    title        = {KInsecta},
    author       = {Professor Roman Garnett},
    year         = 2015,
    howpublished = {\url{https://www.z-u-g.org/aufgaben/ki-leuchttuerme/projektuebersicht-fl2/kinsecta/}}
}
@misc{deep-learning-architectures,
    title = {Learning Deep Architectures for AI},
    author = {Yoshua Bengio},
    year = {2009},
    howpublished = {\url{https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf}}
}


@misc{lecun-bengio,
    title = {Convolutional Networks for Image,s Speech, and Time-Series},
    author = {Yann LeCun, Yoshua Bengio},
    year = {1997},
    howpublished = {\url{http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf}}
}
% Software
@misc{omalley2019kerastuner,
    title        = {KerasTuner},
    author       = {O'Malley, Tom and Bursztein, Elie and Long, James and Chollet, Fran\c{c}ois and Jin, Haifeng and Invernizzi, Luca and others},
    year         = 2019,
    howpublished = {\url{https://github.com/keras-team/keras-tuner}}
}

@misc{Label-Studio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Nikita Shevchenko and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2021},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@article{Jiao_2019,
	doi = {10.1109/access.2019.2939201},
  
	url = {https://doi.org/10.1109%2Faccess.2019.2939201},
  
	year = 2019,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {7},
  
	pages = {128837--128868},
  
	author = {Licheng Jiao and Fan Zhang and Fang Liu and Shuyuan Yang and Lingling Li and Zhixi Feng and Rong Qu},
  
	title = {A Survey of Deep Learning-Based Object Detection},
  
	journal = {{IEEE} Access}
}
@misc{object-detection-optimization,
  doi = {10.48550/ARXIV.1803.08707},
  
  url = {https://arxiv.org/abs/1803.08707},
  
  author = {Soviany, Petru and Ionescu, Radu Tudor},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Optimizing the Trade-off between Single-Stage and Two-Stage Object Detectors using Image Difficulty Prediction},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{batch-normalization,
  doi = {10.48550/ARXIV.1502.03167},
  
  url = {https://arxiv.org/abs/1502.03167},
  
  author = {Ioffe, Sergey and Szegedy, Christian},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@misc{GD-algos,
  doi = {10.48550/ARXIV.1609.04747},
  
  url = {https://arxiv.org/abs/1609.04747},
  
  author = {Ruder, Sebastian},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An overview of gradient descent optimization algorithms},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% Books

%% Hands On

@book{handsOn,
  title = "Hands-On Machine {L}earning with {S}cikit-{L}earn, {K}eras, and {T}ensor{F}low, Second Edition",
  author    = "Aurélien Géron",
  year      = 2019,
  publisher = "O’Reilly Media, Inc",
  address   = "1005 Gravenstein Highway North, Sebastopol, CA 95472",
  isbn      = "978-1-492-03264-9",
}

@book{ml-book,
  title = "Machine Learning mit Python",
  author    = "Sebastian Raschka",
  year      = 2015,
  publisher = "mitp Verlags GmbH",
  isbn      = "978-3-95845-422-4",
}
